Attaching to simple-belk-elasticsearch7.10.1, simple-services_zookeeper_1, simple-services_kafka_1, simple-belk-kibana7.10.1, simple-belk-logstash7.10.1, simple-belk-filebeat7.10.1
zookeeper_1      | zookeeper 21:03:09.85 
kafka_1          |  21:03:10.57 
simple-belk-logstash7.10.1 | Using bundled JDK: /usr/share/logstash/jdk
zookeeper_1      | zookeeper 21:03:09.85 Welcome to the Bitnami zookeeper container
kafka_1          |  21:03:10.57 Welcome to the Bitnami kafka container
zookeeper_1      | zookeeper 21:03:09.86 Subscribe to project updates by watching https://github.com/bitnami/bitnami-docker-zookeeper
zookeeper_1      | zookeeper 21:03:09.86 Submit issues and feature requests at https://github.com/bitnami/bitnami-docker-zookeeper/issues
simple-belk-logstash7.10.1 | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
kafka_1          |  21:03:10.57 Subscribe to project updates by watching https://github.com/bitnami/bitnami-docker-kafka
zookeeper_1      | zookeeper 21:03:09.86 
kafka_1          |  21:03:10.57 Submit issues and feature requests at https://github.com/bitnami/bitnami-docker-kafka/issues
zookeeper_1      | zookeeper 21:03:09.86 INFO  ==> ** Starting ZooKeeper setup **
kafka_1          |  21:03:10.57 
zookeeper_1      | zookeeper 21:03:09.88 WARN  ==> You have set the environment variable ALLOW_ANONYMOUS_LOGIN=yes. For safety reasons, do not use this flag in a production environment.
kafka_1          |  21:03:10.57 INFO  ==> ** Starting Kafka setup **
zookeeper_1      | zookeeper 21:03:09.89 INFO  ==> Initializing ZooKeeper...
kafka_1          |  21:03:10.64 WARN  ==> You set the environment variable ALLOW_PLAINTEXT_LISTENER=yes. For safety reasons, do not use this flag in a production environment.
kafka_1          |  21:03:10.64 INFO  ==> Initializing Kafka...
kafka_1          |  21:03:10.65 INFO  ==> No injected configuration files found, creating default config files
zookeeper_1      | zookeeper 21:03:09.90 INFO  ==> No injected configuration file found, creating default config files...
kafka_1          |  21:03:10.70 INFO  ==> Configuring Kafka for client communications with PLAINTEXT authentication.
kafka_1          |  21:03:10.71 WARN  ==> Client communications are configured using PLAINTEXT listeners. For safety reasons, do not use this in a production environment.
kafka_1          |  21:03:10.71 INFO  ==> ** Kafka setup finished! **
zookeeper_1      | zookeeper 21:03:09.95 INFO  ==> No additional servers were specified. ZooKeeper will run in standalone mode...
kafka_1          | 
zookeeper_1      | zookeeper 21:03:09.95 INFO  ==> Deploying ZooKeeper from scratch...
kafka_1          |  21:03:10.73 INFO  ==> ** Starting Kafka **
zookeeper_1      | zookeeper 21:03:09.96 INFO  ==> ** ZooKeeper setup finished! **
zookeeper_1      | 
zookeeper_1      | zookeeper 21:03:09.97 INFO  ==> ** Starting ZooKeeper **
zookeeper_1      | /opt/bitnami/java/bin/java
zookeeper_1      | ZooKeeper JMX enabled by default
zookeeper_1      | Using config: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
zookeeper_1      | 2021-01-25 21:03:10,478 [myid:] - INFO  [main:QuorumPeerConfig@174] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
zookeeper_1      | 2021-01-25 21:03:10,488 [myid:] - INFO  [main:QuorumPeerConfig@460] - clientPortAddress is 0.0.0.0:2181
zookeeper_1      | 2021-01-25 21:03:10,488 [myid:] - INFO  [main:QuorumPeerConfig@464] - secureClientPort is not set
zookeeper_1      | 2021-01-25 21:03:10,488 [myid:] - INFO  [main:QuorumPeerConfig@480] - observerMasterPort is not set
zookeeper_1      | 2021-01-25 21:03:10,489 [myid:] - INFO  [main:QuorumPeerConfig@497] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider
zookeeper_1      | 2021-01-25 21:03:10,492 [myid:1] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
zookeeper_1      | 2021-01-25 21:03:10,492 [myid:1] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
zookeeper_1      | 2021-01-25 21:03:10,492 [myid:1] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
zookeeper_1      | 2021-01-25 21:03:10,492 [myid:1] - WARN  [main:QuorumPeerMain@138] - Either no config or no quorum defined in config, running in standalone mode
zookeeper_1      | 2021-01-25 21:03:10,495 [myid:1] - INFO  [main:ManagedUtil@44] - Log4j 1.2 jmx support found and enabled.
zookeeper_1      | 2021-01-25 21:03:10,502 [myid:1] - INFO  [main:QuorumPeerConfig@174] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
zookeeper_1      | 2021-01-25 21:03:10,502 [myid:1] - INFO  [main:QuorumPeerConfig@460] - clientPortAddress is 0.0.0.0:2181
zookeeper_1      | 2021-01-25 21:03:10,502 [myid:1] - INFO  [main:QuorumPeerConfig@464] - secureClientPort is not set
zookeeper_1      | 2021-01-25 21:03:10,503 [myid:1] - INFO  [main:QuorumPeerConfig@480] - observerMasterPort is not set
zookeeper_1      | 2021-01-25 21:03:10,503 [myid:1] - INFO  [main:QuorumPeerConfig@497] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider
zookeeper_1      | 2021-01-25 21:03:10,503 [myid:1] - INFO  [main:ZooKeeperServerMain@122] - Starting server
zookeeper_1      | 2021-01-25 21:03:10,513 [myid:1] - INFO  [main:ServerMetrics@62] - ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@236e3f4e
zookeeper_1      | 2021-01-25 21:03:10,516 [myid:1] - INFO  [main:FileTxnSnapLog@124] - zookeeper.snapshot.trust.empty : false
zookeeper_1      | 2021-01-25 21:03:10,525 [myid:1] - INFO  [main:ZookeeperBanner@42] - 
zookeeper_1      | 2021-01-25 21:03:10,525 [myid:1] - INFO  [main:ZookeeperBanner@42] -   ______                  _                                          
zookeeper_1      | 2021-01-25 21:03:10,525 [myid:1] - INFO  [main:ZookeeperBanner@42] -  |___  /                 | |                                         
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -                                               | |                     
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] -                                               |_|                     
zookeeper_1      | 2021-01-25 21:03:10,526 [myid:1] - INFO  [main:ZookeeperBanner@42] - 
zookeeper_1      | 2021-01-25 21:03:10,527 [myid:1] - INFO  [main:Environment@98] - Server environment:zookeeper.version=3.6.2--803c7f1a12f85978cb049af5e4ef23bd8b688715, built on 09/04/2020 12:44 GMT
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:host.name=7b7a63863855
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.version=11.0.9.1
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.vendor=BellSoft
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.home=/opt/bitnami/java
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.class.path=/opt/bitnami/zookeeper/bin/../zookeeper-server/target/classes:/opt/bitnami/zookeeper/bin/../build/classes:/opt/bitnami/zookeeper/bin/../zookeeper-server/target/lib/*.jar:/opt/bitnami/zookeeper/bin/../build/lib/*.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-prometheus-metrics-3.6.2.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-jute-3.6.2.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-3.6.2.jar:/opt/bitnami/zookeeper/bin/../lib/snappy-java-1.1.7.jar:/opt/bitnami/zookeeper/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/bitnami/zookeeper/bin/../lib/slf4j-api-1.7.25.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_servlet-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_hotspot-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_common-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient-0.6.0.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-unix-common-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-epoll-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-resolver-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-handler-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-common-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-codec-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-buffer-4.1.50.Final.jar:/opt/bitnami/zookeeper/bin/../lib/metrics-core-3.2.5.jar:/opt/bitnami/zookeeper/bin/../lib/log4j-1.2.17.jar:/opt/bitnami/zookeeper/bin/../lib/json-simple-1.1.1.jar:/opt/bitnami/zookeeper/bin/../lib/jline-2.14.6.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-util-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-servlet-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-server-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-security-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-io-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-http-9.4.24.v20191120.jar:/opt/bitnami/zookeeper/bin/../lib/javax.servlet-api-3.1.0.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-databind-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-core-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-annotations-2.10.3.jar:/opt/bitnami/zookeeper/bin/../lib/commons-lang-2.6.jar:/opt/bitnami/zookeeper/bin/../lib/commons-cli-1.2.jar:/opt/bitnami/zookeeper/bin/../lib/audience-annotations-0.5.0.jar:/opt/bitnami/zookeeper/bin/../zookeeper-*.jar:/opt/bitnami/zookeeper/bin/../zookeeper-server/src/main/resources/lib/*.jar:/opt/bitnami/zookeeper/bin/../conf:
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.io.tmpdir=/tmp
zookeeper_1      | 2021-01-25 21:03:10,528 [myid:1] - INFO  [main:Environment@98] - Server environment:java.compiler=<NA>
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.name=Linux
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.arch=amd64
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.version=5.8.0-40-generic
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:user.name=?
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:user.home=?
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:user.dir=/
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.free=1009MB
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.max=1024MB
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:Environment@98] - Server environment:os.memory.total=1024MB
zookeeper_1      | 2021-01-25 21:03:10,529 [myid:1] - INFO  [main:ZooKeeperServer@129] - zookeeper.enableEagerACLCheck = false
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@137] - zookeeper.digest.enabled = true
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@141] - zookeeper.closeSessionTxn.enabled = true
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@1444] - zookeeper.flushDelay=0
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@1453] - zookeeper.maxWriteQueuePollTime=0
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@1462] - zookeeper.maxBatchSize=1000
zookeeper_1      | 2021-01-25 21:03:10,530 [myid:1] - INFO  [main:ZooKeeperServer@243] - zookeeper.intBufferStartingSizeBytes = 1024
zookeeper_1      | 2021-01-25 21:03:10,531 [myid:1] - INFO  [main:BlueThrottle@141] - Weighed connection throttling is disabled
zookeeper_1      | 2021-01-25 21:03:10,532 [myid:1] - INFO  [main:ZooKeeperServer@1256] - minSessionTimeout set to 4000
zookeeper_1      | 2021-01-25 21:03:10,532 [myid:1] - INFO  [main:ZooKeeperServer@1265] - maxSessionTimeout set to 40000
zookeeper_1      | 2021-01-25 21:03:10,533 [myid:1] - INFO  [main:ResponseCache@45] - Response cache size is initialized with value 400.
zookeeper_1      | 2021-01-25 21:03:10,533 [myid:1] - INFO  [main:ResponseCache@45] - Response cache size is initialized with value 400.
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@111] - zookeeper.pathStats.slotCapacity = 60
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@112] - zookeeper.pathStats.slotDuration = 15
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@113] - zookeeper.pathStats.maxDepth = 6
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@114] - zookeeper.pathStats.initialDelay = 5
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@115] - zookeeper.pathStats.delay = 5
zookeeper_1      | 2021-01-25 21:03:10,535 [myid:1] - INFO  [main:RequestPathMetricsCollector@116] - zookeeper.pathStats.enabled = false
zookeeper_1      | 2021-01-25 21:03:10,538 [myid:1] - INFO  [main:ZooKeeperServer@1481] - The max bytes for all large requests are set to 104857600
zookeeper_1      | 2021-01-25 21:03:10,538 [myid:1] - INFO  [main:ZooKeeperServer@1495] - The large request threshold is set to -1
zookeeper_1      | 2021-01-25 21:03:10,538 [myid:1] - INFO  [main:ZooKeeperServer@339] - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /bitnami/zookeeper/data/version-2 snapdir /bitnami/zookeeper/data/version-2
zookeeper_1      | 2021-01-25 21:03:10,564 [myid:1] - INFO  [main:Log@169] - Logging initialized @555ms to org.eclipse.jetty.util.log.Slf4jLog
zookeeper_1      | 2021-01-25 21:03:10,644 [myid:1] - WARN  [main:ContextHandler@1520] - o.e.j.s.ServletContextHandler@5e7cd6cc{/,null,UNAVAILABLE} contextPath ends with /*
zookeeper_1      | 2021-01-25 21:03:10,645 [myid:1] - WARN  [main:ContextHandler@1531] - Empty contextPath
zookeeper_1      | 2021-01-25 21:03:10,665 [myid:1] - INFO  [main:Server@359] - jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 11.0.9.1+1-LTS
zookeeper_1      | 2021-01-25 21:03:10,700 [myid:1] - INFO  [main:DefaultSessionIdManager@333] - DefaultSessionIdManager workerName=node0
zookeeper_1      | 2021-01-25 21:03:10,700 [myid:1] - INFO  [main:DefaultSessionIdManager@338] - No SessionScavenger set, using defaults
zookeeper_1      | 2021-01-25 21:03:10,702 [myid:1] - INFO  [main:HouseKeeper@140] - node0 Scavenging every 600000ms
zookeeper_1      | 2021-01-25 21:03:10,705 [myid:1] - WARN  [main:ConstraintSecurityHandler@757] - ServletContext@o.e.j.s.ServletContextHandler@5e7cd6cc{/,null,STARTING} has uncovered http methods for path: /*
zookeeper_1      | 2021-01-25 21:03:10,711 [myid:1] - INFO  [main:ContextHandler@825] - Started o.e.j.s.ServletContextHandler@5e7cd6cc{/,null,AVAILABLE}
zookeeper_1      | 2021-01-25 21:03:10,723 [myid:1] - INFO  [main:AbstractConnector@330] - Started ServerConnector@28261e8e{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
zookeeper_1      | 2021-01-25 21:03:10,724 [myid:1] - INFO  [main:Server@399] - Started @715ms
zookeeper_1      | 2021-01-25 21:03:10,724 [myid:1] - INFO  [main:JettyAdminServer@182] - Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands
zookeeper_1      | 2021-01-25 21:03:10,729 [myid:1] - INFO  [main:ServerCnxnFactory@169] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
zookeeper_1      | 2021-01-25 21:03:10,730 [myid:1] - WARN  [main:ServerCnxnFactory@309] - maxCnxns is not configured, using default value 0.
zookeeper_1      | 2021-01-25 21:03:10,732 [myid:1] - INFO  [main:NIOServerCnxnFactory@666] - Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers.
zookeeper_1      | 2021-01-25 21:03:10,733 [myid:1] - INFO  [main:NIOServerCnxnFactory@674] - binding to port 0.0.0.0/0.0.0.0:2181
zookeeper_1      | 2021-01-25 21:03:10,746 [myid:1] - INFO  [main:WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
zookeeper_1      | 2021-01-25 21:03:10,746 [myid:1] - INFO  [main:WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
zookeeper_1      | 2021-01-25 21:03:10,748 [myid:1] - INFO  [main:ZKDatabase@132] - zookeeper.snapshotSizeFactor = 0.33
zookeeper_1      | 2021-01-25 21:03:10,748 [myid:1] - INFO  [main:ZKDatabase@152] - zookeeper.commitLogCount=500
zookeeper_1      | 2021-01-25 21:03:10,754 [myid:1] - INFO  [main:SnapStream@61] - zookeeper.snapshot.compression.method = CHECKED
zookeeper_1      | 2021-01-25 21:03:10,755 [myid:1] - INFO  [main:FileTxnSnapLog@470] - Snapshotting: 0x0 to /bitnami/zookeeper/data/version-2/snapshot.0
zookeeper_1      | 2021-01-25 21:03:10,759 [myid:1] - INFO  [main:ZKDatabase@289] - Snapshot loaded in 10 ms, highest zxid is 0x0, digest is 1371985504
zookeeper_1      | 2021-01-25 21:03:10,759 [myid:1] - INFO  [main:FileTxnSnapLog@470] - Snapshotting: 0x0 to /bitnami/zookeeper/data/version-2/snapshot.0
zookeeper_1      | 2021-01-25 21:03:10,760 [myid:1] - INFO  [main:ZooKeeperServer@529] - Snapshot taken in 0 ms
zookeeper_1      | 2021-01-25 21:03:10,768 [myid:1] - INFO  [main:RequestThrottler@74] - zookeeper.request_throttler.shutdownTimeout = 10000
zookeeper_1      | 2021-01-25 21:03:10,767 [myid:1] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@136] - PrepRequestProcessor (sid:0) started, reconfigEnabled=false
zookeeper_1      | 2021-01-25 21:03:10,785 [myid:1] - INFO  [main:ContainerManager@83] - Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0
zookeeper_1      | 2021-01-25 21:03:10,786 [myid:1] - INFO  [main:ZKAuditProvider@42] - ZooKeeper audit is disabled.
simple-belk-filebeat7.10.1 | Exiting: error loading config file: config file ("filebeat.yml") must be owned by the user identifier (uid=0) or root
kafka_1          | [2021-01-25 21:03:11,711] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
simple-belk-filebeat7.10.1 exited with code 1
kafka_1          | [2021-01-25 21:03:12,290] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka_1          | [2021-01-25 21:03:12,389] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka_1          | [2021-01-25 21:03:12,393] INFO starting (kafka.server.KafkaServer)
kafka_1          | [2021-01-25 21:03:12,395] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
kafka_1          | [2021-01-25 21:03:12,415] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
kafka_1          | [2021-01-25 21:03:12,420] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,420] INFO Client environment:host.name=6f0530e0da14 (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.version=11.0.9.1 (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.vendor=BellSoft (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.home=/opt/bitnami/java (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.class.path=/opt/bitnami/kafka/bin/../libs/activation-1.1.1.jar:/opt/bitnami/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/bitnami/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/bitnami/kafka/bin/../libs/commons-cli-1.4.jar:/opt/bitnami/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/bitnami/kafka/bin/../libs/connect-api-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-file-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-json-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-mirror-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-mirror-client-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-runtime-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/connect-transforms-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/jackson-annotations-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-core-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-databind-2.10.5.1.jar:/opt/bitnami/kafka/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-module-paranamer-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jackson-module-scala_2.12-2.10.5.jar:/opt/bitnami/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/bitnami/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/bitnami/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/bitnami/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/bitnami/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/bitnami/kafka/bin/../libs/javassist-3.25.0-GA.jar:/opt/bitnami/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/bitnami/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/bitnami/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/bitnami/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/bitnami/kafka/bin/../libs/jersey-client-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-common-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-container-servlet-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-container-servlet-core-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-hk2-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-media-jaxb-2.31.jar:/opt/bitnami/kafka/bin/../libs/jersey-server-2.31.jar:/opt/bitnami/kafka/bin/../libs/jetty-client-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-http-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-io-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-security-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-server-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jetty-util-9.4.33.v20201020.jar:/opt/bitnami/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/bitnami/kafka/bin/../libs/kafka-clients-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-log4j-appender-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-raft-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-examples-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-scala_2.12-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-tools-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/kafka_2.12-2.7.0-sources.jar:/opt/bitnami/kafka/bin/../libs/kafka_2.12-2.7.0.jar:/opt/bitnami/kafka/bin/../libs/log4j-1.2.17.jar:/opt/bitnami/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/bitnami/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/bitnami/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/bitnami/kafka/bin/../libs/netty-buffer-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-codec-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-common-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-handler-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-resolver-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/opt/bitnami/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/bitnami/kafka/bin/../libs/paranamer-2.8.jar:/opt/bitnami/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/bitnami/kafka/bin/../libs/reflections-0.9.12.jar:/opt/bitnami/kafka/bin/../libs/rocksdbjni-5.18.4.jar:/opt/bitnami/kafka/bin/../libs/scala-collection-compat_2.12-2.2.0.jar:/opt/bitnami/kafka/bin/../libs/scala-java8-compat_2.12-0.9.1.jar:/opt/bitnami/kafka/bin/../libs/scala-library-2.12.12.jar:/opt/bitnami/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/bitnami/kafka/bin/../libs/scala-reflect-2.12.12.jar:/opt/bitnami/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/bitnami/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/bitnami/kafka/bin/../libs/snappy-java-1.1.7.7.jar:/opt/bitnami/kafka/bin/../libs/zookeeper-3.5.8.jar:/opt/bitnami/kafka/bin/../libs/zookeeper-jute-3.5.8.jar:/opt/bitnami/kafka/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:os.version=5.8.0-40-generic (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:user.name=? (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:user.home=? (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,421] INFO Client environment:os.memory.free=1013MB (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,422] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,422] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,425] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@495b0487 (org.apache.zookeeper.ZooKeeper)
kafka_1          | [2021-01-25 21:03:12,430] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
kafka_1          | [2021-01-25 21:03:12,436] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
kafka_1          | [2021-01-25 21:03:12,439] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
kafka_1          | [2021-01-25 21:03:12,449] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka_1          | [2021-01-25 21:03:12,459] INFO Socket connection established, initiating session, client: /172.18.0.4:33686, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
zookeeper_1      | 2021-01-25 21:03:12,473 [myid:1] - INFO  [SyncThread:0:FileTxnLog@284] - Creating new log file: log.1
kafka_1          | [2021-01-25 21:03:12,491] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, sessionid = 0x100002945fc0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
kafka_1          | [2021-01-25 21:03:12,495] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
kafka_1          | [2021-01-25 21:03:12,655] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka_1          | [2021-01-25 21:03:12,671] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
kafka_1          | [2021-01-25 21:03:12,672] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
kafka_1          | [2021-01-25 21:03:12,821] INFO Cluster ID = CUpqynL8TiWvTR64rmgqeA (kafka.server.KafkaServer)
kafka_1          | [2021-01-25 21:03:12,831] WARN No meta.properties file under dir /bitnami/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
kafka_1          | [2021-01-25 21:03:12,951] INFO KafkaConfig values: 
kafka_1          | 	advertised.host.name = null
kafka_1          | 	advertised.listeners = CLIENT://kafka:9092,EXTERNAL://localhost:9093
kafka_1          | 	advertised.port = null
kafka_1          | 	alter.config.policy.class.name = null
kafka_1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka_1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka_1          | 	authorizer.class.name = 
kafka_1          | 	auto.create.topics.enable = true
kafka_1          | 	auto.leader.rebalance.enable = true
kafka_1          | 	background.threads = 10
kafka_1          | 	broker.id = -1
kafka_1          | 	broker.id.generation.enable = true
kafka_1          | 	broker.rack = null
kafka_1          | 	client.quota.callback.class = null
kafka_1          | 	compression.type = producer
kafka_1          | 	connection.failed.authentication.delay.ms = 100
kafka_1          | 	connections.max.idle.ms = 600000
kafka_1          | 	connections.max.reauth.ms = 0
kafka_1          | 	control.plane.listener.name = null
kafka_1          | 	controlled.shutdown.enable = true
kafka_1          | 	controlled.shutdown.max.retries = 3
kafka_1          | 	controlled.shutdown.retry.backoff.ms = 5000
kafka_1          | 	controller.quota.window.num = 11
kafka_1          | 	controller.quota.window.size.seconds = 1
kafka_1          | 	controller.socket.timeout.ms = 30000
kafka_1          | 	create.topic.policy.class.name = null
kafka_1          | 	default.replication.factor = 1
kafka_1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka_1          | 	delegation.token.expiry.time.ms = 86400000
kafka_1          | 	delegation.token.master.key = null
kafka_1          | 	delegation.token.max.lifetime.ms = 604800000
kafka_1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka_1          | 	delete.topic.enable = true
kafka_1          | 	fetch.max.bytes = 57671680
kafka_1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka_1          | 	group.initial.rebalance.delay.ms = 0
kafka_1          | 	group.max.session.timeout.ms = 1800000
kafka_1          | 	group.max.size = 2147483647
kafka_1          | 	group.min.session.timeout.ms = 6000
kafka_1          | 	host.name = 
kafka_1          | 	inter.broker.listener.name = CLIENT
kafka_1          | 	inter.broker.protocol.version = 2.7-IV2
kafka_1          | 	kafka.metrics.polling.interval.secs = 10
kafka_1          | 	kafka.metrics.reporters = []
kafka_1          | 	leader.imbalance.check.interval.seconds = 300
kafka_1          | 	leader.imbalance.per.broker.percentage = 10
kafka_1          | 	listener.security.protocol.map = CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka_1          | 	listeners = CLIENT://:9092,EXTERNAL://:9093
kafka_1          | 	log.cleaner.backoff.ms = 15000
kafka_1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka_1          | 	log.cleaner.delete.retention.ms = 86400000
kafka_1          | 	log.cleaner.enable = true
kafka_1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka_1          | 	log.cleaner.io.buffer.size = 524288
kafka_1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka_1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka_1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka_1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka_1          | 	log.cleaner.threads = 1
kafka_1          | 	log.cleanup.policy = [delete]
kafka_1          | 	log.dir = /tmp/kafka-logs
kafka_1          | 	log.dirs = /bitnami/kafka/data
kafka_1          | 	log.flush.interval.messages = 9223372036854775807
kafka_1          | 	log.flush.interval.ms = null
kafka_1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka_1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka_1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka_1          | 	log.index.interval.bytes = 4096
kafka_1          | 	log.index.size.max.bytes = 10485760
kafka_1          | 	log.message.downconversion.enable = true
kafka_1          | 	log.message.format.version = 2.7-IV2
kafka_1          | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka_1          | 	log.message.timestamp.type = CreateTime
kafka_1          | 	log.preallocate = false
kafka_1          | 	log.retention.bytes = -1
kafka_1          | 	log.retention.check.interval.ms = 300000
kafka_1          | 	log.retention.hours = 168
kafka_1          | 	log.retention.minutes = null
kafka_1          | 	log.retention.ms = null
kafka_1          | 	log.roll.hours = 168
kafka_1          | 	log.roll.jitter.hours = 0
kafka_1          | 	log.roll.jitter.ms = null
kafka_1          | 	log.roll.ms = null
kafka_1          | 	log.segment.bytes = 1073741824
kafka_1          | 	log.segment.delete.delay.ms = 60000
kafka_1          | 	max.connection.creation.rate = 2147483647
kafka_1          | 	max.connections = 2147483647
kafka_1          | 	max.connections.per.ip = 2147483647
kafka_1          | 	max.connections.per.ip.overrides = 
kafka_1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka_1          | 	message.max.bytes = 1048588
kafka_1          | 	metric.reporters = []
kafka_1          | 	metrics.num.samples = 2
kafka_1          | 	metrics.recording.level = INFO
kafka_1          | 	metrics.sample.window.ms = 30000
kafka_1          | 	min.insync.replicas = 1
kafka_1          | 	num.io.threads = 8
kafka_1          | 	num.network.threads = 3
kafka_1          | 	num.partitions = 1
kafka_1          | 	num.recovery.threads.per.data.dir = 1
kafka_1          | 	num.replica.alter.log.dirs.threads = null
kafka_1          | 	num.replica.fetchers = 1
kafka_1          | 	offset.metadata.max.bytes = 4096
kafka_1          | 	offsets.commit.required.acks = -1
kafka_1          | 	offsets.commit.timeout.ms = 5000
kafka_1          | 	offsets.load.buffer.size = 5242880
kafka_1          | 	offsets.retention.check.interval.ms = 600000
kafka_1          | 	offsets.retention.minutes = 10080
kafka_1          | 	offsets.topic.compression.codec = 0
kafka_1          | 	offsets.topic.num.partitions = 50
kafka_1          | 	offsets.topic.replication.factor = 1
kafka_1          | 	offsets.topic.segment.bytes = 104857600
kafka_1          | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka_1          | 	password.encoder.iterations = 4096
kafka_1          | 	password.encoder.key.length = 128
kafka_1          | 	password.encoder.keyfactory.algorithm = null
kafka_1          | 	password.encoder.old.secret = null
kafka_1          | 	password.encoder.secret = null
kafka_1          | 	port = 9092
kafka_1          | 	principal.builder.class = null
kafka_1          | 	producer.purgatory.purge.interval.requests = 1000
kafka_1          | 	queued.max.request.bytes = -1
kafka_1          | 	queued.max.requests = 500
kafka_1          | 	quota.consumer.default = 9223372036854775807
kafka_1          | 	quota.producer.default = 9223372036854775807
kafka_1          | 	quota.window.num = 11
kafka_1          | 	quota.window.size.seconds = 1
kafka_1          | 	replica.fetch.backoff.ms = 1000
kafka_1          | 	replica.fetch.max.bytes = 1048576
kafka_1          | 	replica.fetch.min.bytes = 1
kafka_1          | 	replica.fetch.response.max.bytes = 10485760
kafka_1          | 	replica.fetch.wait.max.ms = 500
kafka_1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka_1          | 	replica.lag.time.max.ms = 30000
kafka_1          | 	replica.selector.class = null
kafka_1          | 	replica.socket.receive.buffer.bytes = 65536
kafka_1          | 	replica.socket.timeout.ms = 30000
kafka_1          | 	replication.quota.window.num = 11
kafka_1          | 	replication.quota.window.size.seconds = 1
kafka_1          | 	request.timeout.ms = 30000
kafka_1          | 	reserved.broker.max.id = 1000
kafka_1          | 	sasl.client.callback.handler.class = null
kafka_1          | 	sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
kafka_1          | 	sasl.jaas.config = null
kafka_1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka_1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka_1          | 	sasl.kerberos.service.name = null
kafka_1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka_1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_1          | 	sasl.login.callback.handler.class = null
kafka_1          | 	sasl.login.class = null
kafka_1          | 	sasl.login.refresh.buffer.seconds = 300
kafka_1          | 	sasl.login.refresh.min.period.seconds = 60
kafka_1          | 	sasl.login.refresh.window.factor = 0.8
kafka_1          | 	sasl.login.refresh.window.jitter = 0.05
kafka_1          | 	sasl.mechanism.inter.broker.protocol = 
kafka_1          | 	sasl.server.callback.handler.class = null
kafka_1          | 	security.inter.broker.protocol = PLAINTEXT
kafka_1          | 	security.providers = null
kafka_1          | 	socket.connection.setup.timeout.max.ms = 127000
kafka_1          | 	socket.connection.setup.timeout.ms = 10000
kafka_1          | 	socket.receive.buffer.bytes = 102400
kafka_1          | 	socket.request.max.bytes = 104857600
kafka_1          | 	socket.send.buffer.bytes = 102400
kafka_1          | 	ssl.cipher.suites = []
kafka_1          | 	ssl.client.auth = none
kafka_1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka_1          | 	ssl.endpoint.identification.algorithm = https
kafka_1          | 	ssl.engine.factory.class = null
kafka_1          | 	ssl.key.password = null
kafka_1          | 	ssl.keymanager.algorithm = SunX509
kafka_1          | 	ssl.keystore.certificate.chain = null
kafka_1          | 	ssl.keystore.key = null
kafka_1          | 	ssl.keystore.location = null
kafka_1          | 	ssl.keystore.password = null
kafka_1          | 	ssl.keystore.type = JKS
kafka_1          | 	ssl.principal.mapping.rules = DEFAULT
kafka_1          | 	ssl.protocol = TLSv1.3
kafka_1          | 	ssl.provider = null
kafka_1          | 	ssl.secure.random.implementation = null
kafka_1          | 	ssl.trustmanager.algorithm = PKIX
kafka_1          | 	ssl.truststore.certificates = null
kafka_1          | 	ssl.truststore.location = null
kafka_1          | 	ssl.truststore.password = null
kafka_1          | 	ssl.truststore.type = JKS
kafka_1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka_1          | 	transaction.max.timeout.ms = 900000
kafka_1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka_1          | 	transaction.state.log.load.buffer.size = 5242880
kafka_1          | 	transaction.state.log.min.isr = 1
kafka_1          | 	transaction.state.log.num.partitions = 50
kafka_1          | 	transaction.state.log.replication.factor = 1
kafka_1          | 	transaction.state.log.segment.bytes = 104857600
kafka_1          | 	transactional.id.expiration.ms = 604800000
kafka_1          | 	unclean.leader.election.enable = false
kafka_1          | 	zookeeper.clientCnxnSocket = null
kafka_1          | 	zookeeper.connect = zookeeper:2181
kafka_1          | 	zookeeper.connection.timeout.ms = 18000
kafka_1          | 	zookeeper.max.in.flight.requests = 10
kafka_1          | 	zookeeper.session.timeout.ms = 18000
kafka_1          | 	zookeeper.set.acl = false
kafka_1          | 	zookeeper.ssl.cipher.suites = null
kafka_1          | 	zookeeper.ssl.client.enable = false
kafka_1          | 	zookeeper.ssl.crl.enable = false
kafka_1          | 	zookeeper.ssl.enabled.protocols = null
kafka_1          | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka_1          | 	zookeeper.ssl.keystore.location = null
kafka_1          | 	zookeeper.ssl.keystore.password = null
kafka_1          | 	zookeeper.ssl.keystore.type = null
kafka_1          | 	zookeeper.ssl.ocsp.enable = false
kafka_1          | 	zookeeper.ssl.protocol = TLSv1.2
kafka_1          | 	zookeeper.ssl.truststore.location = null
kafka_1          | 	zookeeper.ssl.truststore.password = null
kafka_1          | 	zookeeper.ssl.truststore.type = null
kafka_1          | 	zookeeper.sync.time.ms = 2000
kafka_1          |  (kafka.server.KafkaConfig)
kafka_1          | [2021-01-25 21:03:12,962] INFO KafkaConfig values: 
kafka_1          | 	advertised.host.name = null
kafka_1          | 	advertised.listeners = CLIENT://kafka:9092,EXTERNAL://localhost:9093
kafka_1          | 	advertised.port = null
kafka_1          | 	alter.config.policy.class.name = null
kafka_1          | 	alter.log.dirs.replication.quota.window.num = 11
kafka_1          | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka_1          | 	authorizer.class.name = 
kafka_1          | 	auto.create.topics.enable = true
kafka_1          | 	auto.leader.rebalance.enable = true
kafka_1          | 	background.threads = 10
kafka_1          | 	broker.id = -1
kafka_1          | 	broker.id.generation.enable = true
kafka_1          | 	broker.rack = null
kafka_1          | 	client.quota.callback.class = null
kafka_1          | 	compression.type = producer
kafka_1          | 	connection.failed.authentication.delay.ms = 100
kafka_1          | 	connections.max.idle.ms = 600000
kafka_1          | 	connections.max.reauth.ms = 0
kafka_1          | 	control.plane.listener.name = null
kafka_1          | 	controlled.shutdown.enable = true
kafka_1          | 	controlled.shutdown.max.retries = 3
kafka_1          | 	controlled.shutdown.retry.backoff.ms = 5000
kafka_1          | 	controller.quota.window.num = 11
kafka_1          | 	controller.quota.window.size.seconds = 1
kafka_1          | 	controller.socket.timeout.ms = 30000
kafka_1          | 	create.topic.policy.class.name = null
kafka_1          | 	default.replication.factor = 1
kafka_1          | 	delegation.token.expiry.check.interval.ms = 3600000
kafka_1          | 	delegation.token.expiry.time.ms = 86400000
kafka_1          | 	delegation.token.master.key = null
kafka_1          | 	delegation.token.max.lifetime.ms = 604800000
kafka_1          | 	delete.records.purgatory.purge.interval.requests = 1
kafka_1          | 	delete.topic.enable = true
kafka_1          | 	fetch.max.bytes = 57671680
kafka_1          | 	fetch.purgatory.purge.interval.requests = 1000
kafka_1          | 	group.initial.rebalance.delay.ms = 0
kafka_1          | 	group.max.session.timeout.ms = 1800000
kafka_1          | 	group.max.size = 2147483647
kafka_1          | 	group.min.session.timeout.ms = 6000
kafka_1          | 	host.name = 
kafka_1          | 	inter.broker.listener.name = CLIENT
kafka_1          | 	inter.broker.protocol.version = 2.7-IV2
kafka_1          | 	kafka.metrics.polling.interval.secs = 10
kafka_1          | 	kafka.metrics.reporters = []
kafka_1          | 	leader.imbalance.check.interval.seconds = 300
kafka_1          | 	leader.imbalance.per.broker.percentage = 10
kafka_1          | 	listener.security.protocol.map = CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
kafka_1          | 	listeners = CLIENT://:9092,EXTERNAL://:9093
kafka_1          | 	log.cleaner.backoff.ms = 15000
kafka_1          | 	log.cleaner.dedupe.buffer.size = 134217728
kafka_1          | 	log.cleaner.delete.retention.ms = 86400000
kafka_1          | 	log.cleaner.enable = true
kafka_1          | 	log.cleaner.io.buffer.load.factor = 0.9
kafka_1          | 	log.cleaner.io.buffer.size = 524288
kafka_1          | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka_1          | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka_1          | 	log.cleaner.min.cleanable.ratio = 0.5
kafka_1          | 	log.cleaner.min.compaction.lag.ms = 0
kafka_1          | 	log.cleaner.threads = 1
kafka_1          | 	log.cleanup.policy = [delete]
kafka_1          | 	log.dir = /tmp/kafka-logs
kafka_1          | 	log.dirs = /bitnami/kafka/data
kafka_1          | 	log.flush.interval.messages = 9223372036854775807
kafka_1          | 	log.flush.interval.ms = null
kafka_1          | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka_1          | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka_1          | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka_1          | 	log.index.interval.bytes = 4096
kafka_1          | 	log.index.size.max.bytes = 10485760
kafka_1          | 	log.message.downconversion.enable = true
kafka_1          | 	log.message.format.version = 2.7-IV2
kafka_1          | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka_1          | 	log.message.timestamp.type = CreateTime
kafka_1          | 	log.preallocate = false
kafka_1          | 	log.retention.bytes = -1
kafka_1          | 	log.retention.check.interval.ms = 300000
kafka_1          | 	log.retention.hours = 168
kafka_1          | 	log.retention.minutes = null
kafka_1          | 	log.retention.ms = null
kafka_1          | 	log.roll.hours = 168
kafka_1          | 	log.roll.jitter.hours = 0
kafka_1          | 	log.roll.jitter.ms = null
kafka_1          | 	log.roll.ms = null
kafka_1          | 	log.segment.bytes = 1073741824
kafka_1          | 	log.segment.delete.delay.ms = 60000
kafka_1          | 	max.connection.creation.rate = 2147483647
kafka_1          | 	max.connections = 2147483647
kafka_1          | 	max.connections.per.ip = 2147483647
kafka_1          | 	max.connections.per.ip.overrides = 
kafka_1          | 	max.incremental.fetch.session.cache.slots = 1000
kafka_1          | 	message.max.bytes = 1048588
kafka_1          | 	metric.reporters = []
kafka_1          | 	metrics.num.samples = 2
kafka_1          | 	metrics.recording.level = INFO
kafka_1          | 	metrics.sample.window.ms = 30000
kafka_1          | 	min.insync.replicas = 1
kafka_1          | 	num.io.threads = 8
kafka_1          | 	num.network.threads = 3
kafka_1          | 	num.partitions = 1
kafka_1          | 	num.recovery.threads.per.data.dir = 1
kafka_1          | 	num.replica.alter.log.dirs.threads = null
kafka_1          | 	num.replica.fetchers = 1
kafka_1          | 	offset.metadata.max.bytes = 4096
kafka_1          | 	offsets.commit.required.acks = -1
kafka_1          | 	offsets.commit.timeout.ms = 5000
kafka_1          | 	offsets.load.buffer.size = 5242880
kafka_1          | 	offsets.retention.check.interval.ms = 600000
kafka_1          | 	offsets.retention.minutes = 10080
kafka_1          | 	offsets.topic.compression.codec = 0
kafka_1          | 	offsets.topic.num.partitions = 50
kafka_1          | 	offsets.topic.replication.factor = 1
kafka_1          | 	offsets.topic.segment.bytes = 104857600
kafka_1          | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka_1          | 	password.encoder.iterations = 4096
kafka_1          | 	password.encoder.key.length = 128
kafka_1          | 	password.encoder.keyfactory.algorithm = null
kafka_1          | 	password.encoder.old.secret = null
kafka_1          | 	password.encoder.secret = null
kafka_1          | 	port = 9092
kafka_1          | 	principal.builder.class = null
kafka_1          | 	producer.purgatory.purge.interval.requests = 1000
kafka_1          | 	queued.max.request.bytes = -1
kafka_1          | 	queued.max.requests = 500
kafka_1          | 	quota.consumer.default = 9223372036854775807
kafka_1          | 	quota.producer.default = 9223372036854775807
kafka_1          | 	quota.window.num = 11
kafka_1          | 	quota.window.size.seconds = 1
kafka_1          | 	replica.fetch.backoff.ms = 1000
kafka_1          | 	replica.fetch.max.bytes = 1048576
kafka_1          | 	replica.fetch.min.bytes = 1
kafka_1          | 	replica.fetch.response.max.bytes = 10485760
kafka_1          | 	replica.fetch.wait.max.ms = 500
kafka_1          | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka_1          | 	replica.lag.time.max.ms = 30000
kafka_1          | 	replica.selector.class = null
kafka_1          | 	replica.socket.receive.buffer.bytes = 65536
kafka_1          | 	replica.socket.timeout.ms = 30000
kafka_1          | 	replication.quota.window.num = 11
kafka_1          | 	replication.quota.window.size.seconds = 1
kafka_1          | 	request.timeout.ms = 30000
kafka_1          | 	reserved.broker.max.id = 1000
kafka_1          | 	sasl.client.callback.handler.class = null
kafka_1          | 	sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
kafka_1          | 	sasl.jaas.config = null
kafka_1          | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_1          | 	sasl.kerberos.min.time.before.relogin = 60000
kafka_1          | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka_1          | 	sasl.kerberos.service.name = null
kafka_1          | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka_1          | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_1          | 	sasl.login.callback.handler.class = null
kafka_1          | 	sasl.login.class = null
kafka_1          | 	sasl.login.refresh.buffer.seconds = 300
kafka_1          | 	sasl.login.refresh.min.period.seconds = 60
kafka_1          | 	sasl.login.refresh.window.factor = 0.8
kafka_1          | 	sasl.login.refresh.window.jitter = 0.05
kafka_1          | 	sasl.mechanism.inter.broker.protocol = 
kafka_1          | 	sasl.server.callback.handler.class = null
kafka_1          | 	security.inter.broker.protocol = PLAINTEXT
kafka_1          | 	security.providers = null
kafka_1          | 	socket.connection.setup.timeout.max.ms = 127000
kafka_1          | 	socket.connection.setup.timeout.ms = 10000
kafka_1          | 	socket.receive.buffer.bytes = 102400
kafka_1          | 	socket.request.max.bytes = 104857600
kafka_1          | 	socket.send.buffer.bytes = 102400
kafka_1          | 	ssl.cipher.suites = []
kafka_1          | 	ssl.client.auth = none
kafka_1          | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka_1          | 	ssl.endpoint.identification.algorithm = https
kafka_1          | 	ssl.engine.factory.class = null
kafka_1          | 	ssl.key.password = null
kafka_1          | 	ssl.keymanager.algorithm = SunX509
kafka_1          | 	ssl.keystore.certificate.chain = null
kafka_1          | 	ssl.keystore.key = null
kafka_1          | 	ssl.keystore.location = null
kafka_1          | 	ssl.keystore.password = null
kafka_1          | 	ssl.keystore.type = JKS
kafka_1          | 	ssl.principal.mapping.rules = DEFAULT
kafka_1          | 	ssl.protocol = TLSv1.3
kafka_1          | 	ssl.provider = null
kafka_1          | 	ssl.secure.random.implementation = null
kafka_1          | 	ssl.trustmanager.algorithm = PKIX
kafka_1          | 	ssl.truststore.certificates = null
kafka_1          | 	ssl.truststore.location = null
kafka_1          | 	ssl.truststore.password = null
kafka_1          | 	ssl.truststore.type = JKS
kafka_1          | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka_1          | 	transaction.max.timeout.ms = 900000
kafka_1          | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka_1          | 	transaction.state.log.load.buffer.size = 5242880
kafka_1          | 	transaction.state.log.min.isr = 1
kafka_1          | 	transaction.state.log.num.partitions = 50
kafka_1          | 	transaction.state.log.replication.factor = 1
kafka_1          | 	transaction.state.log.segment.bytes = 104857600
kafka_1          | 	transactional.id.expiration.ms = 604800000
kafka_1          | 	unclean.leader.election.enable = false
kafka_1          | 	zookeeper.clientCnxnSocket = null
kafka_1          | 	zookeeper.connect = zookeeper:2181
kafka_1          | 	zookeeper.connection.timeout.ms = 18000
kafka_1          | 	zookeeper.max.in.flight.requests = 10
kafka_1          | 	zookeeper.session.timeout.ms = 18000
kafka_1          | 	zookeeper.set.acl = false
kafka_1          | 	zookeeper.ssl.cipher.suites = null
kafka_1          | 	zookeeper.ssl.client.enable = false
kafka_1          | 	zookeeper.ssl.crl.enable = false
kafka_1          | 	zookeeper.ssl.enabled.protocols = null
kafka_1          | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka_1          | 	zookeeper.ssl.keystore.location = null
kafka_1          | 	zookeeper.ssl.keystore.password = null
kafka_1          | 	zookeeper.ssl.keystore.type = null
kafka_1          | 	zookeeper.ssl.ocsp.enable = false
kafka_1          | 	zookeeper.ssl.protocol = TLSv1.2
kafka_1          | 	zookeeper.ssl.truststore.location = null
kafka_1          | 	zookeeper.ssl.truststore.password = null
kafka_1          | 	zookeeper.ssl.truststore.type = null
kafka_1          | 	zookeeper.sync.time.ms = 2000
kafka_1          |  (kafka.server.KafkaConfig)
kafka_1          | [2021-01-25 21:03:13,010] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1          | [2021-01-25 21:03:13,011] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1          | [2021-01-25 21:03:13,013] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1          | [2021-01-25 21:03:13,015] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1          | [2021-01-25 21:03:13,057] INFO Loading logs from log dirs ArrayBuffer(/bitnami/kafka/data) (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:13,059] INFO Attempting recovery for all logs in /bitnami/kafka/data since no clean shutdown file was found (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:13,075] INFO Loaded 0 logs in 18ms. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:13,091] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:13,093] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:13,561] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
kafka_1          | [2021-01-25 21:03:13,564] INFO Created ConnectionAcceptRate-CLIENT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
kafka_1          | [2021-01-25 21:03:13,568] INFO Updated CLIENT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka_1          | [2021-01-25 21:03:13,572] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
kafka_1          | [2021-01-25 21:03:13,606] INFO [SocketServer brokerId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(CLIENT) (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,606] INFO Created ConnectionAcceptRate-EXTERNAL sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
kafka_1          | [2021-01-25 21:03:13,607] INFO Updated EXTERNAL max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka_1          | [2021-01-25 21:03:13,607] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
kafka_1          | [2021-01-25 21:03:13,617] INFO [SocketServer brokerId=1001] Created data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,652] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,653] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,654] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,655] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,670] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka_1          | [2021-01-25 21:03:13,670] INFO [broker-1001-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka_1          | [2021-01-25 21:03:13,699] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
kafka_1          | [2021-01-25 21:03:13,722] INFO Stat of the created znode at /brokers/ids/1001 is: 25,25,1611608593710,1611608593710,1,0,0,72057771305730048,239,0,25
kafka_1          |  (kafka.zk.KafkaZkClient)
kafka_1          | [2021-01-25 21:03:13,723] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: CLIENT://kafka:9092,EXTERNAL://localhost:9093, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
kafka_1          | [2021-01-25 21:03:13,787] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,791] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,792] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,806] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
kafka_1          | [2021-01-25 21:03:13,822] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka_1          | [2021-01-25 21:03:13,823] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka_1          | [2021-01-25 21:03:13,831] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
kafka_1          | [2021-01-25 21:03:13,839] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
kafka_1          | [2021-01-25 21:03:13,859] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka_1          | [2021-01-25 21:03:13,869] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka_1          | [2021-01-25 21:03:13,869] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka_1          | [2021-01-25 21:03:13,899] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1          | [2021-01-25 21:03:13,906] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
kafka_1          | [2021-01-25 21:03:13,915] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka_1          | [2021-01-25 21:03:13,931] INFO [SocketServer brokerId=1001] Starting socket server acceptors and processors (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,937] INFO [SocketServer brokerId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(CLIENT) (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,938] INFO [SocketServer brokerId=1001] Started data-plane acceptor and processor(s) for endpoint : ListenerName(EXTERNAL) (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,939] INFO [SocketServer brokerId=1001] Started socket server acceptors and processors (kafka.network.SocketServer)
kafka_1          | [2021-01-25 21:03:13,946] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1          | [2021-01-25 21:03:13,946] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1          | [2021-01-25 21:03:13,946] INFO Kafka startTimeMs: 1611608593939 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1          | [2021-01-25 21:03:13,948] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
kafka_1          | [2021-01-25 21:03:14,074] INFO [broker-1001-to-controller-send-thread]: Recorded new controller, from now on will use broker 1001 (kafka.server.BrokerToControllerRequestThread)
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:14,348Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "version[7.10.1], pid[8], build[default/docker/1c34507e66d7db1211f66f3513706fdf548736aa/2020-12-05T01:00:33.671820Z], OS[Linux/5.8.0-40-generic/amd64], JVM[AdoptOpenJDK/OpenJDK 64-Bit Server VM/15.0.1/15.0.1+9]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:14,350Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "JVM home [/usr/share/elasticsearch/jdk], using bundled JDK [true]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:14,351Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.locale.providers=SPI,COMPAT, -Xms1g, -Xmx1g, -XX:+UseG1GC, -XX:G1ReservePercent=25, -XX:InitiatingHeapOccupancyPercent=30, -Djava.io.tmpdir=/tmp/elasticsearch-1723200899454953435, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Des.cgroups.hierarchy.override=/, -XX:MaxDirectMemorySize=536870912, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=docker, -Des.bundled_jdk=true]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,931Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [aggs-matrix-stats]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,931Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [analysis-common]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,931Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [constant-keyword]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,932Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [flattened]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,932Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [frozen-indices]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,932Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [ingest-common]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,932Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [ingest-geoip]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,932Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [ingest-user-agent]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,933Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [kibana]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,933Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [lang-expression]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,933Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [lang-mustache]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,933Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [lang-painless]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,934Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [mapper-extras]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,934Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [mapper-version]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,934Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [parent-join]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,935Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [percolator]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,935Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [rank-eval]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,935Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [reindex]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,935Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [repositories-metering-api]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,935Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [repository-url]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,936Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [search-business-rules]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,936Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [searchable-snapshots]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,936Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [spatial]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,937Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [transform]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,937Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [transport-netty4]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,937Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [unsigned-long]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,937Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [vectors]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,937Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [wildcard]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,938Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-analytics]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,938Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-async]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,938Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-async-search]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,938Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-autoscaling]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,938Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-ccr]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-core]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-data-streams]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-deprecation]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-enrich]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-eql]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,939Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-graph]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,940Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-identity-provider]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,940Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-ilm]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,940Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-logstash]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,940Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-ml]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,940Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-monitoring]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,941Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-ql]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,941Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-rollup]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,941Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-security]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,941Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-sql]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,941Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-stack]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,942Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-voting-only-node]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,942Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "loaded module [x-pack-watcher]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:16,943Z", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "no plugins loaded" }
simple-belk-elasticsearch7.10.1 | {"type": "deprecation", "timestamp": "2021-01-25T21:03:16,978Z", "level": "DEPRECATION", "component": "o.e.d.c.s.Settings", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[node.data] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version." }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:17,004Z", "level": "INFO", "component": "o.e.e.NodeEnvironment", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "using [1] data paths, mounts [[/ (overlay)]], net usable_space [85.4gb], net total_space [109gb], types [overlay]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:17,005Z", "level": "INFO", "component": "o.e.e.NodeEnvironment", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "heap size [1gb], compressed ordinary object pointers [true]" }
simple-belk-elasticsearch7.10.1 | {"type": "deprecation", "timestamp": "2021-01-25T21:03:17,007Z", "level": "DEPRECATION", "component": "o.e.d.c.s.Settings", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[node.master] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version." }
simple-belk-elasticsearch7.10.1 | {"type": "deprecation", "timestamp": "2021-01-25T21:03:17,015Z", "level": "DEPRECATION", "component": "o.e.d.c.s.Settings", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[node.ingest] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version." }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:17,063Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "node name [ef6bdc5818da], node ID [pW4URufNQ5OL-kT4tVfcoQ], cluster name [elasticsearch-cluster], roles [transform, master, remote_cluster_client, data, ml, data_content, data_hot, data_warm, data_cold, ingest]" }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["info","plugins-service"],"pid":9,"message":"Plugin \"auditTrail\" is disabled."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["info","plugins-service"],"pid":9,"message":"Plugin \"visTypeXy\" is disabled."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","config","deprecation"],"pid":9,"message":"Config key [monitoring.cluster_alerts.email_notifications.email_address] will be required for email notifications to work in 8.0.\""}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["info","plugins-system"],"pid":9,"message":"Setting up [96] plugins: [usageCollection,telemetryCollectionManager,telemetry,telemetryCollectionXpack,kibanaUsageCollection,xpackLegacy,securityOss,newsfeed,mapsLegacy,kibanaLegacy,taskManager,licensing,globalSearch,globalSearchProviders,code,share,legacyExport,expressions,data,home,console,consoleExtensions,apmOss,observability,cloud,management,indexPatternManagement,advancedSettings,painlessLab,searchprofiler,grokdebugger,savedObjects,fileUpload,embeddable,dashboard,visualizations,visTypeVega,visTypeTimelion,timelion,features,upgradeAssistant,security,snapshotRestore,enterpriseSearch,encryptedSavedObjects,ingestManager,indexManagement,remoteClusters,crossClusterReplication,indexLifecycleManagement,dashboardMode,beatsManagement,transform,ingestPipelines,maps,licenseManagement,graph,dataEnhanced,visTypeTable,visTypeMarkdown,tileMap,regionMap,inputControlVis,visualize,uiActionsEnhanced,esUiShared,charts,visTypeVislib,visTypeTimeseries,rollup,visTypeTagcloud,visTypeMetric,lens,discover,discoverEnhanced,savedObjectsManagement,spaces,reporting,lists,eventLog,actions,case,alerts,stackAlerts,triggersActionsUi,ml,securitySolution,infra,monitoring,logstash,apm,uptime,watcher,bfetch,canvas,translations]"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","security","config"],"pid":9,"message":"Generating a random key for xpack.security.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.security.encryptionKey in kibana.yml"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","security","config"],"pid":9,"message":"Session cookies will be transmitted over insecure connections. This is not recommended."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","encryptedSavedObjects","config"],"pid":9,"message":"Generating a random key for xpack.encryptedSavedObjects.encryptionKey. To be able to decrypt encrypted saved objects attributes after restart, please set xpack.encryptedSavedObjects.encryptionKey in kibana.yml"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","ingestManager"],"pid":9,"message":"Fleet APIs are disabled due to the Encrypted Saved Objects plugin using an ephemeral encryption key. Please set xpack.encryptedSavedObjects.encryptionKey in kibana.yml."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","reporting","config"],"pid":9,"message":"Generating a random key for xpack.reporting.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.reporting.encryptionKey in kibana.yml"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","reporting","config"],"pid":9,"message":"Chromium sandbox provides an additional layer of protection, but is not supported for Linux CentOS 8.2.2004 OS. Automatically setting 'xpack.reporting.capture.browser.chromium.disableSandbox: true'."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","actions","actions"],"pid":9,"message":"APIs are disabled due to the Encrypted Saved Objects plugin using an ephemeral encryption key. Please set xpack.encryptedSavedObjects.encryptionKey in kibana.yml."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["warning","plugins","alerts","plugins","alerting"],"pid":9,"message":"APIs are disabled due to the Encrypted Saved Objects plugin using an ephemeral encryption key. Please set xpack.encryptedSavedObjects.encryptionKey in kibana.yml."}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:20,934Z", "level": "INFO", "component": "o.e.x.m.p.l.CppLogMessageHandler", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[controller/199] [Main.cc@114] controller (64 bit): Version 7.10.1 (Build 11e1ac84105757) Copyright (c) 2020 Elasticsearch BV" }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:20Z","tags":["info","plugins","monitoring","monitoring"],"pid":9,"message":"config sourced from: production cluster"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["info","savedobjects-service"],"pid":9,"message":"Waiting until all Elasticsearch nodes are compatible with Kibana before starting saved objects migrations..."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["error","elasticsearch","monitoring"],"pid":9,"message":"Request error, retrying\nGET http://elasticsearch:9200/_xpack => connect ECONNREFUSED 172.18.0.2:9200"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["warning","elasticsearch","monitoring"],"pid":9,"message":"Unable to revive connection: http://elasticsearch:9200/"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["warning","elasticsearch","monitoring"],"pid":9,"message":"No living connections"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["warning","plugins","licensing"],"pid":9,"message":"License information could not be obtained from Elasticsearch due to Error: No Living connections error"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["warning","plugins","monitoring","monitoring"],"pid":9,"message":"X-Pack Monitoring Cluster Alerts will not be available: No Living connections"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["error","elasticsearch","data"],"pid":9,"message":"[ConnectionError]: connect ECONNREFUSED 172.18.0.2:9200"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:21Z","tags":["error","savedobjects-service"],"pid":9,"message":"Unable to retrieve version information from Elasticsearch nodes."}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:22,100Z", "level": "INFO", "component": "o.e.x.s.a.s.FileRolesStore", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "parsed [0] roles from file [/usr/share/elasticsearch/config/roles.yml]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:22,983Z", "level": "INFO", "component": "o.e.t.NettyAllocator", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=1gb}]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:23,048Z", "level": "INFO", "component": "o.e.d.DiscoveryModule", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "using discovery type [single-node] and seed hosts providers [settings]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:23,405Z", "level": "WARN", "component": "o.e.g.DanglingIndicesState", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually" }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:23Z","tags":["error","elasticsearch","data"],"pid":9,"message":"[ConnectionError]: connect ECONNREFUSED 172.18.0.2:9200"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:23,753Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "initialized" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:23,754Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "starting ..." }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:23,887Z", "level": "INFO", "component": "o.e.t.TransportService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "publish_address {172.18.0.2:9300}, bound_addresses {0.0.0.0:9300}" }
simple-belk-logstash7.10.1 | WARNING: An illegal reflective access operation has occurred
simple-belk-logstash7.10.1 | WARNING: Illegal reflective access by org.jruby.ext.openssl.SecurityHelper (file:/tmp/jruby-1/jruby4894992308051348808jopenssl.jar) to field java.security.MessageDigest.provider
simple-belk-logstash7.10.1 | WARNING: Please consider reporting this to the maintainers of org.jruby.ext.openssl.SecurityHelper
simple-belk-logstash7.10.1 | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
simple-belk-logstash7.10.1 | WARNING: All illegal access operations will be denied in a future release
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,063Z", "level": "WARN", "component": "o.e.b.BootstrapChecks", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,072Z", "level": "INFO", "component": "o.e.c.c.Coordinator", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "setting initial configuration to VotingConfiguration{pW4URufNQ5OL-kT4tVfcoQ}" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,206Z", "level": "INFO", "component": "o.e.c.s.MasterService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "elected-as-master ([1] nodes joined)[{ef6bdc5818da}{pW4URufNQ5OL-kT4tVfcoQ}{wX828qB6SKODqssO9Vl6_A}{172.18.0.2}{172.18.0.2:9300}{cdhilmrstw}{ml.machine_memory=8359108608, xpack.installed=true, transform.node=true, ml.max_open_jobs=20} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, delta: master node changed {previous [], current [{ef6bdc5818da}{pW4URufNQ5OL-kT4tVfcoQ}{wX828qB6SKODqssO9Vl6_A}{172.18.0.2}{172.18.0.2:9300}{cdhilmrstw}{ml.machine_memory=8359108608, xpack.installed=true, transform.node=true, ml.max_open_jobs=20}]}" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,249Z", "level": "INFO", "component": "o.e.c.c.CoordinationState", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "cluster UUID set to [Ii8DTopXQ6GFREwPKWLGag]" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,288Z", "level": "INFO", "component": "o.e.c.s.ClusterApplierService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "master node changed {previous [], current [{ef6bdc5818da}{pW4URufNQ5OL-kT4tVfcoQ}{wX828qB6SKODqssO9Vl6_A}{172.18.0.2}{172.18.0.2:9300}{cdhilmrstw}{ml.machine_memory=8359108608, xpack.installed=true, transform.node=true, ml.max_open_jobs=20}]}, term: 1, version: 1, reason: Publication{term=1, version=1}" }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,328Z", "level": "INFO", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "publish_address {172.18.0.2:9200}, bound_addresses {0.0.0.0:9200}", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,328Z", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "started", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,341Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-anomalies-] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,342Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-state] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,342Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-config] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,343Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-inference-000003] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,344Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-meta] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,345Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-notifications-000001] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,345Z", "level": "INFO", "component": "o.e.x.c.t.IndexTemplateRegistry", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding legacy template [.ml-stats] for [ml], because it doesn't exist", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,413Z", "level": "INFO", "component": "o.e.g.GatewayService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "recovered [0] indices into cluster_state", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,581Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-meta] for index patterns [.ml-meta]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,644Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-state] for index patterns [.ml-state*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,697Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-inference-000003] for index patterns [.ml-inference-000003]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,761Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-config] for index patterns [.ml-config]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,824Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-anomalies-] for index patterns [.ml-anomalies-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,872Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-notifications-000001] for index patterns [.ml-notifications-000001]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,923Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.ml-stats] for index patterns [.ml-stats-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:24,970Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [synthetics-settings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,024Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [metrics-settings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,070Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [logs-settings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,120Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [metrics-mappings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,165Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [synthetics-mappings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,209Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding component template [logs-mappings]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,279Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [.watches] for index patterns [.watches*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,322Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [.triggered_watches] for index patterns [.triggered_watches*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:25,366][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"7.10.1", "jruby.version"=>"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc OpenJDK 64-Bit Server VM 11.0.8+10 on 11.0.8+10 +indy +jit [linux-x86_64]"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,376Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [.watch-history-12] for index patterns [.watcher-history-12*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:25,398][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:25,409][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,421Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [ilm-history] for index patterns [ilm-history-3*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,474Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [.slm-history] for index patterns [.slm-history-3*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,514Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,579Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,623Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,679Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:25,703][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
simple-belk-logstash7.10.1 | [2021-01-25T21:03:25,724][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"269d6f16-07ca-478e-9558-9a7f6b44d2a7", :path=>"/usr/share/logstash/data/uuid"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,729Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,780Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [metrics] for index patterns [metrics-*-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,828Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [synthetics] for index patterns [synthetics-*-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,878Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index template [logs] for index patterns [logs-*-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,926Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [ml-size-based-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:25,982Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [logs]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,025Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [synthetics]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,062Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [metrics]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,103Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [watch-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,140Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [ilm-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,178Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [slm-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,308Z", "level": "INFO", "component": "o.e.l.LicenseService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "license [287f8c3b-0013-4950-89e8-4c93ff0573a3] mode [basic] - valid", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,309Z", "level": "INFO", "component": "o.e.x.s.s.SecurityStatusChangeListener", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "Active license is now [BASIC]; Security is disabled", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Starting saved objects migrations"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Creating index .kibana_task_manager_1."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Creating index .kibana_1."}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,436Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana_task_manager_1] creating index, cause [api], templates [], shards [1]/[1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,446Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "updating number_of_replicas to [0] for indices [.kibana_task_manager_1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,584Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana_1] creating index, cause [api], templates [], shards [1]/[1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,585Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "updating number_of_replicas to [0] for indices [.kibana_1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Pointing alias .kibana_task_manager to .kibana_task_manager_1."}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:26,727Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.kibana_1][0]]]).", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Pointing alias .kibana to .kibana_1."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Finished in 409ms."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","savedobjects-service"],"pid":9,"message":"Finished in 432ms."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","plugins-system"],"pid":9,"message":"Starting [96] plugins: [usageCollection,telemetryCollectionManager,telemetry,telemetryCollectionXpack,kibanaUsageCollection,xpackLegacy,securityOss,newsfeed,mapsLegacy,kibanaLegacy,taskManager,licensing,globalSearch,globalSearchProviders,code,share,legacyExport,expressions,data,home,console,consoleExtensions,apmOss,observability,cloud,management,indexPatternManagement,advancedSettings,painlessLab,searchprofiler,grokdebugger,savedObjects,fileUpload,embeddable,dashboard,visualizations,visTypeVega,visTypeTimelion,timelion,features,upgradeAssistant,security,snapshotRestore,enterpriseSearch,encryptedSavedObjects,ingestManager,indexManagement,remoteClusters,crossClusterReplication,indexLifecycleManagement,dashboardMode,beatsManagement,transform,ingestPipelines,maps,licenseManagement,graph,dataEnhanced,visTypeTable,visTypeMarkdown,tileMap,regionMap,inputControlVis,visualize,uiActionsEnhanced,esUiShared,charts,visTypeVislib,visTypeTimeseries,rollup,visTypeTagcloud,visTypeMetric,lens,discover,discoverEnhanced,savedObjectsManagement,spaces,reporting,lists,eventLog,actions,case,alerts,stackAlerts,triggersActionsUi,ml,securitySolution,infra,monitoring,logstash,apm,uptime,watcher,bfetch,canvas,translations]"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:26Z","tags":["info","plugins","taskManager","taskManager"],"pid":9,"message":"TaskManager is identified by the Kibana UUID: 93eea501-6be9-4766-951b-61aca90b06d3"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,097Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.management-beats] for index patterns [.management-beats]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:27Z","tags":["info","plugins","crossClusterReplication"],"pid":9,"message":"Your basic license does not support crossClusterReplication. Please upgrade your license."}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:27Z","tags":["info","plugins","monitoring","monitoring","kibana-monitoring"],"pid":9,"message":"Starting monitoring stats collection"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:27Z","tags":["info","plugins","watcher"],"pid":9,"message":"Your basic license does not support watcher. Please upgrade your license."}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:27,287][INFO ][org.reflections.Reflections] Reflections took 37 ms to scan 1 urls, producing 23 keys and 47 values 
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,434Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.apm-agent-configuration] creating index, cause [api], templates [], shards [1]/[1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,435Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "updating number_of_replicas to [0] for indices [.apm-agent-configuration]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,498Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.apm-custom-link] creating index, cause [api], templates [], shards [1]/[1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,501Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "updating number_of_replicas to [0] for indices [.apm-custom-link]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,616Z", "level": "INFO", "component": "o.e.c.m.MetadataMappingService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana_task_manager_1/P2J48F_ITsa1-1eXPpg1tA] update_mapping [_doc]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,675Z", "level": "INFO", "component": "o.e.c.m.MetadataMappingService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana_1/GvnbJU64TFGZIwuiy1goLQ] update_mapping [_doc]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,700Z", "level": "INFO", "component": "o.e.c.m.MetadataMappingService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana_1/GvnbJU64TFGZIwuiy1goLQ] update_mapping [_doc]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:27Z","tags":["listening","info"],"pid":9,"message":"Server running at http://0.0.0.0:5601"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,788Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.apm-custom-link][0]]]).", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:27,851][WARN ][deprecation.logstash.outputs.elasticsearch] Relying on default value of `pipeline.ecs_compatibility`, which may change in a future major release of Logstash. To avoid unexpected changes when upgrading Logstash, please explicitly declare your desired ECS Compatibility mode.
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:27,883Z", "level": "INFO", "component": "o.e.x.i.a.TransportPutLifecycleAction", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding index lifecycle policy [kibana-event-log-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,238][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch:9200/]}}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,394][WARN ][logstash.outputs.elasticsearch][main] Restored connection to ES instance {:url=>"http://elasticsearch:9200/"}
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:28Z","tags":["info","http","server","Kibana"],"pid":9,"message":"http server running at http://0.0.0.0:5601"}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,443][INFO ][logstash.outputs.elasticsearch][main] ES Output version determined {:es_version=>7}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,444Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [.kibana-event-log-7.10.1-template] for index patterns [.kibana-event-log-7.10.1-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,445][WARN ][logstash.outputs.elasticsearch][main] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>7}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,521][INFO ][logstash.outputs.elasticsearch][main] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["http://elasticsearch:9200"]}
simple-belk-elasticsearch7.10.1 | {"type": "deprecation", "timestamp": "2021-01-25T21:03:28,533Z", "level": "DEPRECATION", "component": "o.e.d.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "index name [.kibana-event-log-7.10.1-000001] starts with a dot '.', in the next major version, index names starting with a dot are reserved for hidden indices and system indices", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,539Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[.kibana-event-log-7.10.1-000001] creating index, cause [api], templates [.kibana-event-log-7.10.1-template], shards [1]/[1]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,541Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "updating number_of_replicas to [0] for indices [.kibana-event-log-7.10.1-000001]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,571][INFO ][logstash.outputs.elasticsearch][main] Using a default mapping template {:es_version=>7, :ecs_compatibility=>:disabled}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,629][INFO ][logstash.outputs.elasticsearch][main] Attempting to install template {:manage_template=>{"index_patterns"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s", "number_of_shards"=>1}, "mappings"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,649][INFO ][logstash.outputs.elasticsearch][main] Installing elasticsearch template to _template/logstash
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,668Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [.kibana-event-log-7.10.1-000001] from [null] to [{\"phase\":\"new\",\"action\":\"complete\",\"name\":\"complete\"}] in policy [kibana-event-log-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,743][INFO ][logstash.filters.geoip   ][main] Using geoip database {:path=>"/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-filter-geoip-6.0.3-java/vendor/GeoLite2-City.mmdb"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,799Z", "level": "INFO", "component": "o.e.c.m.MetadataIndexTemplateService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "adding template [logstash] for index patterns [logstash-*]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-logstash7.10.1 | [2021-01-25T21:03:28,845][INFO ][logstash.javapipeline    ][main] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>12, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>1500, "pipeline.sources"=>["/usr/share/logstash/pipeline/logstash.conf"], :thread=>"#<Thread:0x420ad2e5 run>"}
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,874Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.kibana-event-log-7.10.1-000001][0]]]).", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,918Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [.kibana-event-log-7.10.1-000001] from [{\"phase\":\"new\",\"action\":\"complete\",\"name\":\"complete\"}] to [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-indexing-complete\"}] in policy [kibana-event-log-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:28,972Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [.kibana-event-log-7.10.1-000001] from [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-indexing-complete\"}] to [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-follow-shard-tasks\"}] in policy [kibana-event-log-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-kibana7.10.1 | {"type":"log","@timestamp":"2021-01-25T21:03:29Z","tags":["warning","plugins","reporting"],"pid":9,"message":"Enabling the Chromium sandbox provides an additional layer of protection."}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:29,964][INFO ][logstash.javapipeline    ][main] Pipeline Java execution initialization time {"seconds"=>1.12}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:29,981][INFO ][logstash.inputs.beats    ][main] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:29,996][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,085][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,148][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] ConsumerConfig values: 
simple-belk-logstash7.10.1 | 	allow.auto.create.topics = true
simple-belk-logstash7.10.1 | 	auto.commit.interval.ms = 5000
simple-belk-logstash7.10.1 | 	auto.offset.reset = latest
simple-belk-logstash7.10.1 | 	bootstrap.servers = [kafka:9092]
simple-belk-logstash7.10.1 | 	check.crcs = true
simple-belk-logstash7.10.1 | 	client.dns.lookup = default
simple-belk-logstash7.10.1 | 	client.id = logstash-0
simple-belk-logstash7.10.1 | 	client.rack = 
simple-belk-logstash7.10.1 | 	connections.max.idle.ms = 540000
simple-belk-logstash7.10.1 | 	default.api.timeout.ms = 60000
simple-belk-logstash7.10.1 | 	enable.auto.commit = true
simple-belk-logstash7.10.1 | 	exclude.internal.topics = true
simple-belk-logstash7.10.1 | 	fetch.max.bytes = 52428800
simple-belk-logstash7.10.1 | 	fetch.max.wait.ms = 500
simple-belk-logstash7.10.1 | 	fetch.min.bytes = 1
simple-belk-logstash7.10.1 | 	group.id = logstash
simple-belk-logstash7.10.1 | 	group.instance.id = null
simple-belk-logstash7.10.1 | 	heartbeat.interval.ms = 3000
simple-belk-logstash7.10.1 | 	interceptor.classes = []
simple-belk-logstash7.10.1 | 	internal.leave.group.on.close = true
simple-belk-logstash7.10.1 | 	isolation.level = read_uncommitted
simple-belk-logstash7.10.1 | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simple-belk-logstash7.10.1 | 	max.partition.fetch.bytes = 1048576
simple-belk-logstash7.10.1 | 	max.poll.interval.ms = 300000
simple-belk-logstash7.10.1 | 	max.poll.records = 500
simple-belk-logstash7.10.1 | 	metadata.max.age.ms = 300000
simple-belk-logstash7.10.1 | 	metric.reporters = []
simple-belk-logstash7.10.1 | 	metrics.num.samples = 2
simple-belk-logstash7.10.1 | 	metrics.recording.level = INFO
simple-belk-logstash7.10.1 | 	metrics.sample.window.ms = 30000
simple-belk-logstash7.10.1 | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
simple-belk-logstash7.10.1 | 	receive.buffer.bytes = 32768
simple-belk-logstash7.10.1 | 	reconnect.backoff.max.ms = 50
simple-belk-logstash7.10.1 | 	reconnect.backoff.ms = 50
simple-belk-logstash7.10.1 | 	request.timeout.ms = 40000
simple-belk-logstash7.10.1 | 	retry.backoff.ms = 100
simple-belk-logstash7.10.1 | 	sasl.client.callback.handler.class = null
simple-belk-logstash7.10.1 | 	sasl.jaas.config = null
simple-belk-logstash7.10.1 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simple-belk-logstash7.10.1 | 	sasl.kerberos.min.time.before.relogin = 60000
simple-belk-logstash7.10.1 | 	sasl.kerberos.service.name = null
simple-belk-logstash7.10.1 | 	sasl.kerberos.ticket.renew.jitter = 0.05
simple-belk-logstash7.10.1 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simple-belk-logstash7.10.1 | 	sasl.login.callback.handler.class = null
simple-belk-logstash7.10.1 | 	sasl.login.class = null
simple-belk-logstash7.10.1 | 	sasl.login.refresh.buffer.seconds = 300
simple-belk-logstash7.10.1 | 	sasl.login.refresh.min.period.seconds = 60
simple-belk-logstash7.10.1 | 	sasl.login.refresh.window.factor = 0.8
simple-belk-logstash7.10.1 | 	sasl.login.refresh.window.jitter = 0.05
simple-belk-logstash7.10.1 | 	sasl.mechanism = GSSAPI
simple-belk-logstash7.10.1 | 	security.protocol = PLAINTEXT
simple-belk-logstash7.10.1 | 	security.providers = null
simple-belk-logstash7.10.1 | 	send.buffer.bytes = 131072
simple-belk-logstash7.10.1 | 	session.timeout.ms = 10000
simple-belk-logstash7.10.1 | 	ssl.cipher.suites = null
simple-belk-logstash7.10.1 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
simple-belk-logstash7.10.1 | 	ssl.endpoint.identification.algorithm = https
simple-belk-logstash7.10.1 | 	ssl.key.password = null
simple-belk-logstash7.10.1 | 	ssl.keymanager.algorithm = SunX509
simple-belk-logstash7.10.1 | 	ssl.keystore.location = null
simple-belk-logstash7.10.1 | 	ssl.keystore.password = null
simple-belk-logstash7.10.1 | 	ssl.keystore.type = JKS
simple-belk-logstash7.10.1 | 	ssl.protocol = TLS
simple-belk-logstash7.10.1 | 	ssl.provider = null
simple-belk-logstash7.10.1 | 	ssl.secure.random.implementation = null
simple-belk-logstash7.10.1 | 	ssl.trustmanager.algorithm = PKIX
simple-belk-logstash7.10.1 | 	ssl.truststore.location = null
simple-belk-logstash7.10.1 | 	ssl.truststore.password = null
simple-belk-logstash7.10.1 | 	ssl.truststore.type = JKS
simple-belk-logstash7.10.1 | 	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simple-belk-logstash7.10.1 | 
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,179][INFO ][org.logstash.beats.Server][main][d0a0a8c5bb140e8c06bceba20e40e5ade4864048bad265070c55c5f3037bd79c] Starting server on port: 5044
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,296][INFO ][org.apache.kafka.common.utils.AppInfoParser][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] Kafka version: 2.4.1
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,296][INFO ][org.apache.kafka.common.utils.AppInfoParser][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] Kafka commitId: c57222ae8cd7866b
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,296][INFO ][org.apache.kafka.common.utils.AppInfoParser][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] Kafka startTimeMs: 1611608610292
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,309][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Subscribed to topic(s): log
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,470][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
kafka_1          | [2021-01-25 21:03:30,585] INFO Creating topic log with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1          | [2021-01-25 21:03:30,601] INFO [KafkaApi-1001] Auto creation of topic log with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,616][WARN ][org.apache.kafka.clients.NetworkClient][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Error while fetching metadata with correlation id 2 : {log=LEADER_NOT_AVAILABLE}
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,618][INFO ][org.apache.kafka.clients.Metadata][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Cluster ID: CUpqynL8TiWvTR64rmgqeA
kafka_1          | [2021-01-25 21:03:30,620] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(1001), 32 -> ArrayBuffer(1001), 41 -> ArrayBuffer(1001), 17 -> ArrayBuffer(1001), 8 -> ArrayBuffer(1001), 35 -> ArrayBuffer(1001), 44 -> ArrayBuffer(1001), 26 -> ArrayBuffer(1001), 11 -> ArrayBuffer(1001), 29 -> ArrayBuffer(1001), 38 -> ArrayBuffer(1001), 47 -> ArrayBuffer(1001), 20 -> ArrayBuffer(1001), 2 -> ArrayBuffer(1001), 5 -> ArrayBuffer(1001), 14 -> ArrayBuffer(1001), 46 -> ArrayBuffer(1001), 49 -> ArrayBuffer(1001), 40 -> ArrayBuffer(1001), 13 -> ArrayBuffer(1001), 4 -> ArrayBuffer(1001), 22 -> ArrayBuffer(1001), 31 -> ArrayBuffer(1001), 16 -> ArrayBuffer(1001), 7 -> ArrayBuffer(1001), 43 -> ArrayBuffer(1001), 25 -> ArrayBuffer(1001), 34 -> ArrayBuffer(1001), 10 -> ArrayBuffer(1001), 37 -> ArrayBuffer(1001), 1 -> ArrayBuffer(1001), 19 -> ArrayBuffer(1001), 28 -> ArrayBuffer(1001), 45 -> ArrayBuffer(1001), 27 -> ArrayBuffer(1001), 36 -> ArrayBuffer(1001), 18 -> ArrayBuffer(1001), 9 -> ArrayBuffer(1001), 21 -> ArrayBuffer(1001), 48 -> ArrayBuffer(1001), 3 -> ArrayBuffer(1001), 12 -> ArrayBuffer(1001), 30 -> ArrayBuffer(1001), 39 -> ArrayBuffer(1001), 15 -> ArrayBuffer(1001), 42 -> ArrayBuffer(1001), 24 -> ArrayBuffer(1001), 6 -> ArrayBuffer(1001), 33 -> ArrayBuffer(1001), 0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
kafka_1          | [2021-01-25 21:03:30,635] INFO [KafkaApi-1001] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
kafka_1          | [2021-01-25 21:03:30,674] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(log-0) (kafka.server.ReplicaFetcherManager)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:30,722][WARN ][org.apache.kafka.clients.NetworkClient][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Error while fetching metadata with correlation id 4 : {log=LEADER_NOT_AVAILABLE}
kafka_1          | [2021-01-25 21:03:30,759] INFO [Log partition=log-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,767] INFO Created log for partition log-0 in /bitnami/kafka/data/log-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,768] INFO [Partition log-0 broker=1001] No checkpointed highwatermark is found for partition log-0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,769] INFO [Partition log-0 broker=1001] Log loaded for partition log-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,840] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
kafka_1          | [2021-01-25 21:03:30,844] INFO [Log partition=__consumer_offsets-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,845] INFO Created log for partition __consumer_offsets-0 in /bitnami/kafka/data/__consumer_offsets-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,846] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,846] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,851] INFO [Log partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,853] INFO Created log for partition __consumer_offsets-29 in /bitnami/kafka/data/__consumer_offsets-29 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,853] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,853] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,860] INFO [Log partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,861] INFO Created log for partition __consumer_offsets-48 in /bitnami/kafka/data/__consumer_offsets-48 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,862] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,862] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,868] INFO [Log partition=__consumer_offsets-10, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,870] INFO Created log for partition __consumer_offsets-10 in /bitnami/kafka/data/__consumer_offsets-10 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,870] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,870] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,877] INFO [Log partition=__consumer_offsets-45, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,878] INFO Created log for partition __consumer_offsets-45 in /bitnami/kafka/data/__consumer_offsets-45 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,878] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,878] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,887] INFO [Log partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,888] INFO Created log for partition __consumer_offsets-26 in /bitnami/kafka/data/__consumer_offsets-26 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,888] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,888] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,895] INFO [Log partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,896] INFO Created log for partition __consumer_offsets-7 in /bitnami/kafka/data/__consumer_offsets-7 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,896] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,896] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,904] INFO [Log partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,906] INFO Created log for partition __consumer_offsets-42 in /bitnami/kafka/data/__consumer_offsets-42 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,906] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,907] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,913] INFO [Log partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,915] INFO Created log for partition __consumer_offsets-4 in /bitnami/kafka/data/__consumer_offsets-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,915] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,915] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,922] INFO [Log partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,923] INFO Created log for partition __consumer_offsets-23 in /bitnami/kafka/data/__consumer_offsets-23 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,923] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,923] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,931] INFO [Log partition=__consumer_offsets-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,932] INFO Created log for partition __consumer_offsets-1 in /bitnami/kafka/data/__consumer_offsets-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,933] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,933] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,940] INFO [Log partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,942] INFO Created log for partition __consumer_offsets-20 in /bitnami/kafka/data/__consumer_offsets-20 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,942] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,942] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,948] INFO [Log partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,949] INFO Created log for partition __consumer_offsets-39 in /bitnami/kafka/data/__consumer_offsets-39 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,949] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,949] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,956] INFO [Log partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,958] INFO Created log for partition __consumer_offsets-17 in /bitnami/kafka/data/__consumer_offsets-17 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,958] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,958] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,965] INFO [Log partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,966] INFO Created log for partition __consumer_offsets-36 in /bitnami/kafka/data/__consumer_offsets-36 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,966] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,966] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,973] INFO [Log partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,974] INFO Created log for partition __consumer_offsets-14 in /bitnami/kafka/data/__consumer_offsets-14 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,974] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,974] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,982] INFO [Log partition=__consumer_offsets-33, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,983] INFO Created log for partition __consumer_offsets-33 in /bitnami/kafka/data/__consumer_offsets-33 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,983] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,983] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,991] INFO [Log partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:30,992] INFO Created log for partition __consumer_offsets-49 in /bitnami/kafka/data/__consumer_offsets-49 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:30,992] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,992] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:30,998] INFO [Log partition=__consumer_offsets-11, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,000] INFO Created log for partition __consumer_offsets-11 in /bitnami/kafka/data/__consumer_offsets-11 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,000] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,000] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,007] INFO [Log partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,008] INFO Created log for partition __consumer_offsets-30 in /bitnami/kafka/data/__consumer_offsets-30 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,008] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,008] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,016] INFO [Log partition=__consumer_offsets-46, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,017] INFO Created log for partition __consumer_offsets-46 in /bitnami/kafka/data/__consumer_offsets-46 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,017] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,017] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,025] INFO [Log partition=__consumer_offsets-27, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,026] INFO Created log for partition __consumer_offsets-27 in /bitnami/kafka/data/__consumer_offsets-27 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,026] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,026] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,033] INFO [Log partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,034] INFO Created log for partition __consumer_offsets-8 in /bitnami/kafka/data/__consumer_offsets-8 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,034] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,034] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,041] INFO [Log partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,043] INFO Created log for partition __consumer_offsets-24 in /bitnami/kafka/data/__consumer_offsets-24 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,043] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,043] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,048] INFO [Log partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,049] INFO Created log for partition __consumer_offsets-43 in /bitnami/kafka/data/__consumer_offsets-43 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,049] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,049] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,055] INFO [Log partition=__consumer_offsets-5, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,056] INFO Created log for partition __consumer_offsets-5 in /bitnami/kafka/data/__consumer_offsets-5 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,057] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,057] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,064] INFO [Log partition=__consumer_offsets-21, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,065] INFO Created log for partition __consumer_offsets-21 in /bitnami/kafka/data/__consumer_offsets-21 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,065] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,065] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,072] INFO [Log partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,072] INFO Created log for partition __consumer_offsets-40 in /bitnami/kafka/data/__consumer_offsets-40 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,073] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,073] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,080] INFO [Log partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,081] INFO Created log for partition __consumer_offsets-2 in /bitnami/kafka/data/__consumer_offsets-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,081] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,082] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,089] INFO [Log partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,090] INFO Created log for partition __consumer_offsets-37 in /bitnami/kafka/data/__consumer_offsets-37 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,090] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,090] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,097] INFO [Log partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,098] INFO Created log for partition __consumer_offsets-18 in /bitnami/kafka/data/__consumer_offsets-18 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,098] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,098] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,105] INFO [Log partition=__consumer_offsets-34, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,106] INFO Created log for partition __consumer_offsets-34 in /bitnami/kafka/data/__consumer_offsets-34 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,106] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,106] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,113] INFO [Log partition=__consumer_offsets-15, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,114] INFO Created log for partition __consumer_offsets-15 in /bitnami/kafka/data/__consumer_offsets-15 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,115] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,115] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,121] INFO [Log partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,122] INFO Created log for partition __consumer_offsets-12 in /bitnami/kafka/data/__consumer_offsets-12 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,122] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,122] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,129] INFO [Log partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,130] INFO Created log for partition __consumer_offsets-31 in /bitnami/kafka/data/__consumer_offsets-31 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,130] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,131] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,137] INFO [Log partition=__consumer_offsets-9, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,139] INFO Created log for partition __consumer_offsets-9 in /bitnami/kafka/data/__consumer_offsets-9 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,139] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,139] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,145] INFO [Log partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,146] INFO Created log for partition __consumer_offsets-47 in /bitnami/kafka/data/__consumer_offsets-47 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,146] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,147] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,152] INFO [Log partition=__consumer_offsets-19, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,153] INFO Created log for partition __consumer_offsets-19 in /bitnami/kafka/data/__consumer_offsets-19 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,153] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,153] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,159] INFO [Log partition=__consumer_offsets-28, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,160] INFO Created log for partition __consumer_offsets-28 in /bitnami/kafka/data/__consumer_offsets-28 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,160] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,160] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,166] INFO [Log partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,167] INFO Created log for partition __consumer_offsets-38 in /bitnami/kafka/data/__consumer_offsets-38 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,167] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,167] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,174] INFO [Log partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,175] INFO Created log for partition __consumer_offsets-35 in /bitnami/kafka/data/__consumer_offsets-35 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,175] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,175] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,181] INFO [Log partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,182] INFO Created log for partition __consumer_offsets-6 in /bitnami/kafka/data/__consumer_offsets-6 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,182] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,182] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,190] INFO [Log partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,190] INFO Created log for partition __consumer_offsets-44 in /bitnami/kafka/data/__consumer_offsets-44 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,190] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,191] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,197] INFO [Log partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,198] INFO Created log for partition __consumer_offsets-25 in /bitnami/kafka/data/__consumer_offsets-25 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,198] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,198] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,206] INFO [Log partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,208] INFO Created log for partition __consumer_offsets-16 in /bitnami/kafka/data/__consumer_offsets-16 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,208] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,208] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,215] INFO [Log partition=__consumer_offsets-22, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,216] INFO Created log for partition __consumer_offsets-22 in /bitnami/kafka/data/__consumer_offsets-22 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,216] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,216] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,222] INFO [Log partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,223] INFO Created log for partition __consumer_offsets-41 in /bitnami/kafka/data/__consumer_offsets-41 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,223] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,223] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,230] INFO [Log partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,231] INFO Created log for partition __consumer_offsets-32 in /bitnami/kafka/data/__consumer_offsets-32 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,231] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,231] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,239] INFO [Log partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,240] INFO Created log for partition __consumer_offsets-3 in /bitnami/kafka/data/__consumer_offsets-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,240] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,240] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,246] INFO [Log partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
kafka_1          | [2021-01-25 21:03:31,247] INFO Created log for partition __consumer_offsets-13 in /bitnami/kafka/data/__consumer_offsets-13 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
kafka_1          | [2021-01-25 21:03:31,247] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,247] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafka_1          | [2021-01-25 21:03:31,252] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,254] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,255] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,256] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,258] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 6 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,259] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,260] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,261] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 7 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,262] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,263] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,264] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,265] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 9 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,265] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,265] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,265] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,265] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 10 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,266] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka_1          | [2021-01-25 21:03:31,267] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,343][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Discovered group coordinator kafka:9092 (id: 2147482646 rack: null)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,347][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] (Re-)joining group
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,378][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] (Re-)joining group
kafka_1          | [2021-01-25 21:03:31,384] INFO [GroupCoordinator 1001]: Preparing to rebalance group logstash in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member logstash-0-4fae80c5-185d-4491-ac57-930bd785365e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
kafka_1          | [2021-01-25 21:03:31,393] INFO [GroupCoordinator 1001]: Stabilized group logstash generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,399][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Finished assignment for group at generation 1: {logstash-0-4fae80c5-185d-4491-ac57-930bd785365e=Assignment(partitions=[log-0])}
kafka_1          | [2021-01-25 21:03:31,404] INFO [GroupCoordinator 1001]: Assignment received from leader for group logstash for generation 1 (kafka.coordinator.group.GroupCoordinator)
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,450][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Successfully joined group with generation 1
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,454][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Adding newly assigned partitions: log-0
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,466][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Found no committed offset for partition log-0
simple-belk-logstash7.10.1 | [2021-01-25T21:03:31,482][INFO ][org.apache.kafka.clients.consumer.internals.SubscriptionState][main][9d5fb13f45a135212304f7c17a56dad2d92f46ec7ab86de0522862b0fba09d3f] [Consumer clientId=logstash-0, groupId=logstash] Resetting offset for partition log-0 to offset 0.
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:32,503Z", "level": "INFO", "component": "o.e.c.m.MetadataCreateIndexService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "[ilm-history-3-000001] creating index, cause [api], templates [ilm-history], shards [1]/[0]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:32,560Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [ilm-history-3-000001] from [null] to [{\"phase\":\"new\",\"action\":\"complete\",\"name\":\"complete\"}] in policy [ilm-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:32,612Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [ilm-history-3-000001] from [{\"phase\":\"new\",\"action\":\"complete\",\"name\":\"complete\"}] to [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-indexing-complete\"}] in policy [ilm-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:32,652Z", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[ilm-history-3-000001][0]]]).", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }
simple-belk-elasticsearch7.10.1 | {"type": "server", "timestamp": "2021-01-25T21:03:32,686Z", "level": "INFO", "component": "o.e.x.i.IndexLifecycleTransition", "cluster.name": "elasticsearch-cluster", "node.name": "ef6bdc5818da", "message": "moving index [ilm-history-3-000001] from [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-indexing-complete\"}] to [{\"phase\":\"hot\",\"action\":\"unfollow\",\"name\":\"wait-for-follow-shard-tasks\"}] in policy [ilm-history-ilm-policy]", "cluster.uuid": "Ii8DTopXQ6GFREwPKWLGag", "node.id": "pW4URufNQ5OL-kT4tVfcoQ"  }

